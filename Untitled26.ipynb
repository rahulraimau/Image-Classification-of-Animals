{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4h9-0caFXd8",
        "outputId": "5e3bde4c-bae7-4784-8d43-a7ec4c7a2452"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 146MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Train Loss: 1.3176 | Val Loss: 0.3980 | Val Acc: 0.9175\n",
            "Saved best model.\n",
            "Epoch 2/20 | Train Loss: 0.4054 | Val Loss: 0.2566 | Val Acc: 0.9330\n",
            "Saved best model.\n",
            "Epoch 3/20 | Train Loss: 0.2735 | Val Loss: 0.1819 | Val Acc: 0.9433\n",
            "Saved best model.\n",
            "Epoch 4/20 | Train Loss: 0.1898 | Val Loss: 0.1904 | Val Acc: 0.9485\n",
            "Epoch 5/20 | Train Loss: 0.1596 | Val Loss: 0.1271 | Val Acc: 0.9639\n",
            "Saved best model.\n",
            "Epoch 6/20 | Train Loss: 0.1247 | Val Loss: 0.1269 | Val Acc: 0.9691\n",
            "Saved best model.\n",
            "Epoch 7/20 | Train Loss: 0.1114 | Val Loss: 0.1333 | Val Acc: 0.9639\n",
            "Epoch 8/20 | Train Loss: 0.1059 | Val Loss: 0.1223 | Val Acc: 0.9588\n",
            "Saved best model.\n",
            "Epoch 9/20 | Train Loss: 0.0713 | Val Loss: 0.1212 | Val Acc: 0.9588\n",
            "Saved best model.\n",
            "Epoch 10/20 | Train Loss: 0.0976 | Val Loss: 0.0993 | Val Acc: 0.9742\n",
            "Saved best model.\n",
            "Epoch 11/20 | Train Loss: 0.1050 | Val Loss: 0.1027 | Val Acc: 0.9742\n",
            "Epoch 12/20 | Train Loss: 0.0636 | Val Loss: 0.1034 | Val Acc: 0.9639\n",
            "Epoch 13/20 | Train Loss: 0.0666 | Val Loss: 0.0800 | Val Acc: 0.9691\n",
            "Saved best model.\n",
            "Epoch 14/20 | Train Loss: 0.0623 | Val Loss: 0.1186 | Val Acc: 0.9588\n",
            "Epoch 15/20 | Train Loss: 0.0749 | Val Loss: 0.0654 | Val Acc: 0.9794\n",
            "Saved best model.\n",
            "Epoch 16/20 | Train Loss: 0.0526 | Val Loss: 0.1088 | Val Acc: 0.9588\n",
            "Epoch 17/20 | Train Loss: 0.0549 | Val Loss: 0.0937 | Val Acc: 0.9639\n",
            "Epoch 18/20 | Train Loss: 0.0355 | Val Loss: 0.0930 | Val Acc: 0.9639\n",
            "Epoch 19/20 | Train Loss: 0.0415 | Val Loss: 0.0677 | Val Acc: 0.9742\n",
            "Epoch 20/20 | Train Loss: 0.0258 | Val Loss: 0.0906 | Val Acc: 0.9639\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Bear       1.00      1.00      1.00        12\n",
            "        Bird       0.82      1.00      0.90        14\n",
            "         Cat       1.00      0.90      0.95        10\n",
            "         Cow       1.00      1.00      1.00        15\n",
            "        Deer       1.00      1.00      1.00        12\n",
            "         Dog       1.00      1.00      1.00        11\n",
            "     Dolphin       1.00      1.00      1.00        13\n",
            "    Elephant       0.94      0.94      0.94        17\n",
            "     Giraffe       0.94      1.00      0.97        15\n",
            "       Horse       1.00      0.93      0.96        14\n",
            "    Kangaroo       1.00      0.92      0.96        12\n",
            "        Lion       1.00      0.92      0.96        12\n",
            "       Panda       1.00      1.00      1.00        17\n",
            "       Tiger       1.00      1.00      1.00        11\n",
            "       Zebra       1.00      1.00      1.00         9\n",
            "\n",
            "    accuracy                           0.97       194\n",
            "   macro avg       0.98      0.97      0.98       194\n",
            "weighted avg       0.98      0.97      0.97       194\n",
            "\n",
            "Confusion Matrix:\n",
            " [[12  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 14  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  9  0  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0 15  0  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0 12  0  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0 11  0  0  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0 13  0  0  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0 16  0  0  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0 15  0  0  0  0  0  0]\n",
            " [ 0  1  0  0  0  0  0  0  0 13  0  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  1  0 11  0  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  1  0  0  0 11  0  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0 17  0  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 11  0]\n",
            " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  9]]\n",
            "Top-2 Accuracy: 0.9897\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets, models\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, confusion_matrix, top_k_accuracy_score\n",
        "\n",
        "# 1. Configuration\n",
        "DATA_DIR = Path(\"/content/drive/MyDrive/Animal Classification/dataset\")  # replace with your root folder\n",
        "BATCH_SIZE = 32\n",
        "NUM_CLASSES = 15\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 20\n",
        "MODEL_SAVE_PATH = \"best_model.pth\"\n",
        "\n",
        "# 2. Data transforms (ImageNet normalization)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# 3. Dataset & loaders (assumes train/val folders or use torch.utils.data.random_split)\n",
        "full_dataset = datasets.ImageFolder(DATA_DIR, transform=train_transform)\n",
        "class_names = full_dataset.classes\n",
        "\n",
        "# Simple stratified split\n",
        "num_total = len(full_dataset)\n",
        "num_val = int(0.1 * num_total)\n",
        "num_test = int(0.1 * num_total)\n",
        "num_train = num_total - num_val - num_test\n",
        "\n",
        "train_set, val_set, test_set = torch.utils.data.random_split(\n",
        "    full_dataset,\n",
        "    [num_train, num_val, num_test],\n",
        "    generator=torch.Generator().manual_seed(42)\n",
        ")\n",
        "# Replace val/test transforms\n",
        "val_set.dataset.transform = val_transform\n",
        "test_set.dataset.transform = val_transform\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# 4. Baseline model: pretrained ResNet50\n",
        "model = models.resnet50(pretrained=True)\n",
        "# Freeze backbone initially\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace head\n",
        "in_features = model.fc.in_features\n",
        "model.fc = nn.Sequential(\n",
        "    nn.Linear(in_features, 256),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.4),\n",
        "    nn.Linear(256, NUM_CLASSES)\n",
        ")\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "# 5. Loss, optimizer, scheduler\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5, verbose=True)\n",
        "\n",
        "# 6. Training loop with validation\n",
        "best_val_loss = float(\"inf\")\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    running_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "    train_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    correct = 0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item() * images.size(0)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    val_loss /= len(val_loader.dataset)\n",
        "    val_acc = correct / len(val_loader.dataset)\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
        "        print(\"Saved best model.\")\n",
        "\n",
        "# 7. Evaluation on test set\n",
        "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_probs = []\n",
        "all_labels = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "        outputs = model(images)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_probs.extend(probs.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "# Top-2 accuracy (optional)\n",
        "top2 = top_k_accuracy_score(all_labels, np.array(all_probs), k=2, labels=range(NUM_CLASSES))\n",
        "print(f\"Top-2 Accuracy: {top2:.4f}\")\n",
        "\n",
        "# 8. Inference utility\n",
        "from PIL import Image\n",
        "\n",
        "def predict_image(image_path, model, class_names, transform, device):\n",
        "    model.eval()\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    inp = transform(img).unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        out = model(inp)\n",
        "        probs = torch.softmax(out, dim=1)[0]\n",
        "        top_prob, top_idx = torch.topk(probs, 3)\n",
        "    return [(class_names[i], top_prob[i].item()) for i in top_idx]\n",
        "\n",
        "# Example usage:\n",
        "# preds = predict_image(\"some_image.jpg\", model, class_names, val_transform, DEVICE)\n",
        "# print(preds)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}